<?xml version="1.0" encoding="UTF-8"?>
<!--
/**
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * "License"); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
-->
<configuration supports_final="true">


  <property>
    <name>policy_user</name>
    <value>ambari-qa</value>
    <display-name>Policy user for HDFS</display-name>
    <description>This user must be system user and also present at Ranger
			admin portal</description>
    <on-ambari-upgrade add="true"/>
  </property>

  <property>
    <name>hadoop.rpc.protection</name>
    <value>authentication</value>
    <description>Used for repository creation on ranger admin</description>
    <value-attributes>
      <empty-value-valid>true</empty-value-valid>
    </value-attributes>
    <on-ambari-upgrade add="true" />
  </property>

  <property>
    <name>common.name.for.certificate</name>
    <value/>
    <description>Common name for certificate, this value should match what is specified in repo within ranger admin</description>
    <value-attributes>
      <empty-value-valid>true</empty-value-valid>
    </value-attributes>
    <on-ambari-upgrade add="true"/>
  </property>
  <property>
    <name>ranger-hdfs-plugin-enabled</name>
    <value>No</value>
    <display-name>Enable Ranger for HDFS</display-name>
    <description>Enable ranger hdfs plugin</description>
    <depends-on>
      <property>
        <type>ranger-env</type>
        <name>ranger-hdfs-plugin-enabled</name>
      </property>
    </depends-on>
    <value-attributes>
      <type>boolean</type>
      <overridable>false</overridable>
    </value-attributes>
    <on-ambari-upgrade add="true"/>
  </property>


  <property>
    <name>REPOSITORY_CONFIG_USERNAME</name>
    <value>hadoop</value>
    <display-name>Ranger repository config user</display-name>
    <description>Used for repository creation on ranger admin
		</description>
    <on-ambari-upgrade add="true"/>
  </property>
  <property>
    <name>REPOSITORY_CONFIG_PASSWORD</name>
    <value>hadoop</value>
    <display-name>Ranger repository config password</display-name>
    <property-type>PASSWORD</property-type>
    <description>Used for repository creation on ranger admin
		</description>
    <value-attributes>
      <type>password</type>
    </value-attributes>
    <on-ambari-upgrade add="true"/>
  </property>


    <property>
    <name>nfs.file.dump.dir</name>
    <value>/tmp/.hdfs-nfs</value>
    <display-name>NFSGateway dump directory</display-name>
    <description>
      This directory is used to temporarily save out-of-order writes before
      writing to HDFS. For each file, the out-of-order writes are dumped after
      they are accumulated to exceed certain threshold (e.g., 1MB) in memory.
      One needs to make sure the directory has enough space.
    </description>
    <value-attributes>
      <type>directory</type>
    </value-attributes>
    <on-ambari-upgrade add="true"/>
  </property>
  <property>
    <name>nfs.exports.allowed.hosts</name>
    <value>* rw</value>
    <description>
      By default, the export can be mounted by any client. To better control the access,
      users can update the following property. The value string contains machine name and access privilege,
      separated by whitespace characters. Machine name format can be single host, wildcards, and IPv4
      networks.The access privilege uses rw or ro to specify readwrite or readonly access of the machines
      to exports. If the access privilege is not provided, the default is read-only. Entries are separated
      by &quot;;&quot;. For example: &quot;192.168.0.0/22 rw ; host*.example.com ; host1.test.org ro;&quot;.
    </description>
    <display-name>Allowed hosts</display-name>
    <on-ambari-upgrade add="true"/>
  </property>
  <property>
    <name>dfs.encrypt.data.transfer.cipher.suites</name>
    <value>AES/CTR/NoPadding</value>
    <description>
      This value may be either undefined or AES/CTR/NoPadding. If defined, then
      dfs.encrypt.data.transfer uses the specified cipher suite for data encryption.
      If not defined, then only the algorithm specified in dfs.encrypt.data.transfer.algorithm
      is used. By default, the property is not defined.
    </description>
    <on-ambari-upgrade add="true"/>
  </property>
  <property>
    <name>dfs.namenode.inode.attributes.provider.class</name>
    <description>Enable ranger hdfs plugin</description>
    <depends-on>
      <property>
        <type>ranger-hdfs-plugin-properties</type>
        <name>ranger-hdfs-plugin-enabled</name>
      </property>
    </depends-on>
    <value-attributes>
      <overridable>false</overridable>
    </value-attributes>
    <on-ambari-upgrade add="true"/>
  </property>



</configuration>
